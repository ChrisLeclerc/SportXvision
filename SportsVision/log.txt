2025-12-05 16:22:54 
2025-12-05 16:22:54 [6/6] Training started!
2025-12-05 16:22:54 ================================================================================
2025-12-05 16:22:54 [Epoch 1/1000] Training:   0%|                                                                            | 0/1347 [00:00<?, ?it/s]/home/o_a38510/ML/SportsVision/src/train.py:61: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
2025-12-05 16:22:57   with torch.cuda.amp.autocast(enabled=config.training.use_amp):
2025-12-05 16:22:59 [Epoch 1/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:49<00:00,  7.96it/s, loss=0.0477, lr=2.00e-04]
2025-12-05 16:25:43 
2025-12-05 16:25:43 [Epoch 1] Train - Loss: 0.0639, LR: 2.00e-04
2025-12-05 16:25:43 ================================================================================
2025-12-05 16:25:43 [Epoch 2/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:40<00:00,  8.37it/s, loss=0.0439, lr=2.00e-04]
2025-12-05 16:28:24 
2025-12-05 16:28:24 [Epoch 2] Train - Loss: 0.0453, LR: 2.00e-04
2025-12-05 16:28:24 ================================================================================
2025-12-05 16:28:24 [Epoch 3/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:42<00:00,  8.30it/s, loss=0.0414, lr=1.99e-04]
2025-12-05 16:31:06 
2025-12-05 16:31:06 [Epoch 3] Train - Loss: 0.0433, LR: 1.99e-04
2025-12-05 16:31:06 ================================================================================
2025-12-05 16:31:06 [Epoch 4/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:45<00:00,  8.13it/s, loss=0.0439, lr=1.99e-04]
2025-12-05 16:33:52 
2025-12-05 16:33:52 [Epoch 4] Train - Loss: 0.0422, LR: 1.99e-04
2025-12-05 16:33:52 ================================================================================
2025-12-05 16:33:52 [Epoch 5/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:47<00:00,  8.04it/s, loss=0.0376, lr=1.99e-04]
2025-12-05 16:36:40 
2025-12-05 16:36:40 [Epoch 5] Train - Loss: 0.0414, LR: 1.99e-04
2025-12-05 16:36:40 [Epoch 5/1000] Running validation...
2025-12-05 16:36:40 Validation: 100%|██████████████████████████████████████████████████████████████████████████████████| 88/88 [00:13<00:00,  6.47it/s]
2025-12-05 16:37:44 
2025-12-05 16:37:44 [Validation Results]
2025-12-05 16:37:44   Val Loss: 0.0307
2025-12-05 16:37:44   Conf Loss: 0.0307
2025-12-05 16:37:44   mAP (tight): 0.4477
2025-12-05 16:37:44   mAP (loose): 0.6923
2025-12-05 16:37:44   mAP@1s: 0.4173
2025-12-05 16:37:44   mAP@2s: 0.4782
2025-12-05 16:37:44   mAP@3s: 0.5182
2025-12-05 16:37:44   mAP@5s: 0.5782
2025-12-05 16:37:44   mAP@10s: 0.6566
2025-12-05 16:37:44   mAP@20s: 0.7293
2025-12-05 16:37:44   mAP@30s: 0.7648
2025-12-05 16:37:44   mAP@60s: 0.8220
2025-12-05 16:37:46   ✓ Saved best model (mAP: 0.6923)
2025-12-05 16:37:46 ================================================================================
2025-12-05 16:37:46 [Epoch 6/1000] Training:   3%|█▎                                       | 45/1347 [00:07<03:15,  6.66it/s, loss=0.0439, lr=1.99e-04]wandb: WARNING Tried to log to step 5 that is less than the current step 6. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 16:37:54 [Epoch 6/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:49<00:00,  7.93it/s, loss=0.0398, lr=1.99e-04]
2025-12-05 16:40:36 
2025-12-05 16:40:36 [Epoch 6] Train - Loss: 0.0410, LR: 1.99e-04
2025-12-05 16:40:36 ================================================================================
2025-12-05 16:40:36 [Epoch 7/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:36<00:00,  8.58it/s, loss=0.0373, lr=1.99e-04]
2025-12-05 16:43:13 
2025-12-05 16:43:13 [Epoch 7] Train - Loss: 0.0403, LR: 1.99e-04
2025-12-05 16:43:13 ================================================================================
2025-12-05 16:43:13 [Epoch 8/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:36<00:00,  8.60it/s, loss=0.0326, lr=1.98e-04]
2025-12-05 16:45:49 
2025-12-05 16:45:49 [Epoch 8] Train - Loss: 0.0397, LR: 1.98e-04
2025-12-05 16:45:49 ================================================================================
2025-12-05 16:45:49 [Epoch 9/1000] Training: 100%|███████████████████████████████████████| 1347/1347 [02:33<00:00,  8.78it/s, loss=0.0414, lr=1.98e-04]
2025-12-05 16:48:23 
2025-12-05 16:48:23 [Epoch 9] Train - Loss: 0.0396, LR: 1.98e-04
2025-12-05 16:48:23 ================================================================================
2025-12-05 16:48:23 [Epoch 10/1000] Training: 100%|██████████████████████████████████████| 1347/1347 [02:37<00:00,  8.54it/s, loss=0.0495, lr=1.98e-04]
2025-12-05 16:51:01 
2025-12-05 16:51:01 [Epoch 10] Train - Loss: 0.0389, LR: 1.98e-04
2025-12-05 16:51:01 [Epoch 10/1000] Running validation...
2025-12-05 16:51:01 Validation: 100%|██████████████████████████████████████████████████████████████████████████████████| 88/88 [00:14<00:00,  6.06it/s]
2025-12-05 16:52:03 
2025-12-05 16:52:03 [Validation Results]
2025-12-05 16:52:03   Val Loss: 0.0291
2025-12-05 16:52:03   Conf Loss: 0.0291
2025-12-05 16:52:03   mAP (tight): 0.4739
2025-12-05 16:52:03   mAP (loose): 0.7090
2025-12-05 16:52:03   mAP@1s: 0.4389
2025-12-05 16:52:03   mAP@2s: 0.5089
2025-12-05 16:52:03   mAP@3s: 0.5453
2025-12-05 16:52:03   mAP@5s: 0.6026
2025-12-05 16:52:03   mAP@10s: 0.6826
2025-12-05 16:52:03   mAP@20s: 0.7446
2025-12-05 16:52:03   mAP@30s: 0.7767
2025-12-05 16:52:03   mAP@60s: 0.8280
2025-12-05 16:52:04 wandb: WARNING Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 16:52:05   ✓ Saved best model (mAP: 0.7090)
2025-12-05 16:52:07   ✓ Saved checkpoint at epoch 10
2025-12-05 16:52:07 ================================================================================
2025-12-05 16:52:07 [Epoch 11/1000] Training: 100%|██████████████████████████████████████| 1347/1347 [02:32<00:00,  8.84it/s, loss=0.0344, lr=1.98e-04]
2025-12-05 16:54:40 
2025-12-05 16:54:40 [Epoch 11] Train - Loss: 0.0386, LR: 1.98e-04
2025-12-05 16:54:40 ================================================================================
2025-12-05 16:54:40 [Epoch 12/1000] Training: 100%|██████████████████████████████████████| 1347/1347 [02:35<00:00,  8.65it/s, loss=0.0362, lr=1.98e-04]
2025-12-05 16:57:15 
2025-12-05 16:57:15 [Epoch 12] Train - Loss: 0.0381, LR: 1.98e-04
2025-12-05 16:57:15 ================================================================================
2025-12-05 16:57:15 [Epoch 13/1000] Training: 100%|██████████████████████████████████████| 1347/1347 [02:45<00:00,  8.12it/s, loss=0.0376, lr=1.97e-04]
2025-12-05 17:00:01 
2025-12-05 17:00:01 [Epoch 13] Train - Loss: 0.0379, LR: 1.97e-04
2025-12-05 17:00:01 ================================================================================
2025-12-05 17:00:01 [Epoch 14/1000] Training: 100%|██████████████████████████████████████| 1347/1347 [02:46<00:00,  8.09it/s, loss=0.0382, lr=1.97e-04]
2025-12-05 17:02:48 
2025-12-05 17:02:48 [Epoch 14] Train - Loss: 0.0375, LR: 1.97e-04
2025-12-05 17:02:48 ================================================================================
2025-12-05 17:02:48 [Epoch 15/1000] Training: 100%|██████████████████████████████████████| 1347/1347 [02:48<00:00,  7.99it/s, loss=0.0369, lr=1.97e-04]
2025-12-05 17:05:37 
2025-12-05 17:05:37 [Epoch 15] Train - Loss: 0.0372, LR: 1.97e-04
2025-12-05 17:05:37 [Epoch 15/1000] Running validation...
2025-12-05 17:05:37 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:16<00:00,  5.38it/s]
2025-12-05 17:06:47 
2025-12-05 17:06:47 [Validation Results]
2025-12-05 17:06:47   Val Loss: 0.0293
2025-12-05 17:06:47   Conf Loss: 0.0293
2025-12-05 17:06:47   mAP (tight): 0.4938
2025-12-05 17:06:47   mAP (loose): 0.7235
2025-12-05 17:06:47   mAP@1s: 0.4563
2025-12-05 17:06:47   mAP@2s: 0.5313
2025-12-05 17:06:47   mAP@3s: 0.5703
2025-12-05 17:06:47   mAP@5s: 0.6222
2025-12-05 17:06:47   mAP@10s: 0.6977
2025-12-05 17:06:47   mAP@20s: 0.7613
2025-12-05 17:06:47   mAP@30s: 0.7917
2025-12-05 17:06:47   mAP@60s: 0.8346
2025-12-05 17:06:48   ✓ Saved best model (mAP: 0.7235)
2025-12-05 17:06:48 ================================================================================
2025-12-05 17:06:48 [Epoch 16/1000] Training:   2%|█▉                                                                                                     | 26/1347 [00:05<03:22,  6.54it/s, loss=0.0360, lr=1.97e-04]wandb: WARNING Tried to log to step 15 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 17:06:54 [Epoch 16/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:43<00:00,  8.21it/s, loss=0.0344, lr=1.97e-04]
2025-12-05 17:09:32 
2025-12-05 17:09:32 [Epoch 16] Train - Loss: 0.0369, LR: 1.97e-04
2025-12-05 17:09:32 ================================================================================
2025-12-05 17:09:32 [Epoch 17/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.67it/s, loss=0.0373, lr=1.97e-04]
2025-12-05 17:12:08 
2025-12-05 17:12:08 [Epoch 17] Train - Loss: 0.0364, LR: 1.97e-04
2025-12-05 17:12:08 ================================================================================
2025-12-05 17:12:08 [Epoch 18/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:33<00:00,  8.79it/s, loss=0.0332, lr=1.96e-04]
2025-12-05 17:14:41 
2025-12-05 17:14:41 [Epoch 18] Train - Loss: 0.0362, LR: 1.96e-04
2025-12-05 17:14:41 ================================================================================
2025-12-05 17:14:41 [Epoch 19/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:40<00:00,  8.37it/s, loss=0.0383, lr=1.96e-04]
2025-12-05 17:17:22 
2025-12-05 17:17:22 [Epoch 19] Train - Loss: 0.0360, LR: 1.96e-04
2025-12-05 17:17:22 ================================================================================
2025-12-05 17:17:22 [Epoch 20/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:39<00:00,  8.42it/s, loss=0.0396, lr=1.96e-04]
2025-12-05 17:20:02 
2025-12-05 17:20:02 [Epoch 20] Train - Loss: 0.0357, LR: 1.96e-04
2025-12-05 17:20:02 [Epoch 20/1000] Running validation...
2025-12-05 17:20:02 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:12<00:00,  6.90it/s]
2025-12-05 17:21:08 
2025-12-05 17:21:08 [Validation Results]
2025-12-05 17:21:08   Val Loss: 0.0295
2025-12-05 17:21:08   Conf Loss: 0.0295
2025-12-05 17:21:08   mAP (tight): 0.5266
2025-12-05 17:21:08   mAP (loose): 0.7447
2025-12-05 17:21:08   mAP@1s: 0.4923
2025-12-05 17:21:08   mAP@2s: 0.5609
2025-12-05 17:21:08   mAP@3s: 0.5985
2025-12-05 17:21:08   mAP@5s: 0.6498
2025-12-05 17:21:08   mAP@10s: 0.7195
2025-12-05 17:21:08   mAP@20s: 0.7791
2025-12-05 17:21:08   mAP@30s: 0.8047
2025-12-05 17:21:08   mAP@60s: 0.8505
2025-12-05 17:21:09   ✓ Saved best model (mAP: 0.7447)
2025-12-05 17:21:11   ✓ Saved checkpoint at epoch 20
2025-12-05 17:21:11 ================================================================================
2025-12-05 17:21:11 [Epoch 21/1000] Training:   0%|▍                                                                                                       | 6/1347 [00:02<06:00,  3.72it/s, loss=0.0275, lr=1.96e-04]wandb: WARNING Tried to log to step 20 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 17:21:14 [Epoch 21/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:38<00:00,  8.48it/s, loss=0.0361, lr=1.96e-04]
2025-12-05 17:23:50 
2025-12-05 17:23:50 [Epoch 21] Train - Loss: 0.0354, LR: 1.96e-04
2025-12-05 17:23:50 ================================================================================
2025-12-05 17:23:50 [Epoch 22/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:40<00:00,  8.41it/s, loss=0.0391, lr=1.96e-04]
2025-12-05 17:26:30 
2025-12-05 17:26:30 [Epoch 22] Train - Loss: 0.0351, LR: 1.96e-04
2025-12-05 17:26:30 ================================================================================
2025-12-05 17:26:30 [Epoch 23/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:37<00:00,  8.54it/s, loss=0.0326, lr=1.95e-04]
2025-12-05 17:29:08 
2025-12-05 17:29:08 [Epoch 23] Train - Loss: 0.0351, LR: 1.95e-04
2025-12-05 17:29:08 ================================================================================
2025-12-05 17:29:08 [Epoch 24/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.64it/s, loss=0.0347, lr=1.95e-04]
2025-12-05 17:31:44 
2025-12-05 17:31:44 [Epoch 24] Train - Loss: 0.0348, LR: 1.95e-04
2025-12-05 17:31:44 ================================================================================
2025-12-05 17:31:44 [Epoch 25/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:36<00:00,  8.63it/s, loss=0.0286, lr=1.95e-04]
2025-12-05 17:34:20 
2025-12-05 17:34:20 [Epoch 25] Train - Loss: 0.0345, LR: 1.95e-04
2025-12-05 17:34:20 [Epoch 25/1000] Running validation...
2025-12-05 17:34:20 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:13<00:00,  6.70it/s]
2025-12-05 17:35:27 
2025-12-05 17:35:27 [Validation Results]
2025-12-05 17:35:27   Val Loss: 0.0298
2025-12-05 17:35:27   Conf Loss: 0.0298
2025-12-05 17:35:27   mAP (tight): 0.5009
2025-12-05 17:35:27   mAP (loose): 0.7256
2025-12-05 17:35:27   mAP@1s: 0.4687
2025-12-05 17:35:27   mAP@2s: 0.5332
2025-12-05 17:35:27   mAP@3s: 0.5721
2025-12-05 17:35:27   mAP@5s: 0.6246
2025-12-05 17:35:27   mAP@10s: 0.6944
2025-12-05 17:35:27   mAP@20s: 0.7616
2025-12-05 17:35:27   mAP@30s: 0.7909
2025-12-05 17:35:27   mAP@60s: 0.8375
2025-12-05 17:35:27 ================================================================================
2025-12-05 17:35:27 [Epoch 26/1000] Training:   3%|██▉                                                                                                    | 39/1347 [00:07<03:00,  7.26it/s, loss=0.0265, lr=1.95e-04]wandb: WARNING Tried to log to step 25 that is less than the current step 26. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 17:35:34 [Epoch 26/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:39<00:00,  8.42it/s, loss=0.0312, lr=1.95e-04]
2025-12-05 17:38:07 
2025-12-05 17:38:07 [Epoch 26] Train - Loss: 0.0344, LR: 1.95e-04
2025-12-05 17:38:07 ================================================================================
2025-12-05 17:38:07 [Epoch 27/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.68it/s, loss=0.0337, lr=1.95e-04]
2025-12-05 17:40:42 
2025-12-05 17:40:42 [Epoch 27] Train - Loss: 0.0342, LR: 1.95e-04
2025-12-05 17:40:42 ================================================================================
2025-12-05 17:40:42 [Epoch 28/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.65it/s, loss=0.0357, lr=1.94e-04]
2025-12-05 17:43:17 
2025-12-05 17:43:17 [Epoch 28] Train - Loss: 0.0338, LR: 1.94e-04
2025-12-05 17:43:17 ================================================================================
2025-12-05 17:43:17 [Epoch 29/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:28<00:00,  9.05it/s, loss=0.0318, lr=1.94e-04]
2025-12-05 17:45:46 
2025-12-05 17:45:46 [Epoch 29] Train - Loss: 0.0337, LR: 1.94e-04
2025-12-05 17:45:46 ================================================================================
2025-12-05 17:45:46 [Epoch 30/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:31<00:00,  8.88it/s, loss=0.0365, lr=1.94e-04]
2025-12-05 17:48:18 
2025-12-05 17:48:18 [Epoch 30] Train - Loss: 0.0339, LR: 1.94e-04
2025-12-05 17:48:18 [Epoch 30/1000] Running validation...
2025-12-05 17:48:18 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:12<00:00,  6.94it/s]
2025-12-05 17:49:18 
2025-12-05 17:49:18 [Validation Results]
2025-12-05 17:49:18   Val Loss: 0.0322
2025-12-05 17:49:18   Conf Loss: 0.0322
2025-12-05 17:49:18   mAP (tight): 0.5293
2025-12-05 17:49:18   mAP (loose): 0.7533
2025-12-05 17:49:18   mAP@1s: 0.4910
2025-12-05 17:49:18   mAP@2s: 0.5676
2025-12-05 17:49:18   mAP@3s: 0.6055
2025-12-05 17:49:18   mAP@5s: 0.6554
2025-12-05 17:49:18   mAP@10s: 0.7221
2025-12-05 17:49:18   mAP@20s: 0.7856
2025-12-05 17:49:18   mAP@30s: 0.8157
2025-12-05 17:49:18   mAP@60s: 0.8649
2025-12-05 17:49:19   ✓ Saved best model (mAP: 0.7533)
2025-12-05 17:49:21   ✓ Saved checkpoint at epoch 30
2025-12-05 17:49:21 ================================================================================
2025-12-05 17:49:21 [Epoch 31/1000] Training:   1%|▌                                                                                                       | 7/1347 [00:02<05:11,  4.31it/s, loss=0.0385, lr=1.94e-04]wandb: WARNING Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 17:49:24 [Epoch 31/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:46<00:00,  8.08it/s, loss=0.0298, lr=1.94e-04]
2025-12-05 17:52:08 
2025-12-05 17:52:08 [Epoch 31] Train - Loss: 0.0338, LR: 1.94e-04
2025-12-05 17:52:08 ================================================================================
2025-12-05 17:52:08 [Epoch 32/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:29<00:00,  8.98it/s, loss=0.0317, lr=1.94e-04]
2025-12-05 17:54:38 
2025-12-05 17:54:38 [Epoch 32] Train - Loss: 0.0337, LR: 1.94e-04
2025-12-05 17:54:38 ================================================================================
2025-12-05 17:54:38 [Epoch 33/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:29<00:00,  8.99it/s, loss=0.0321, lr=1.93e-04]
2025-12-05 17:57:07 
2025-12-05 17:57:07 [Epoch 33] Train - Loss: 0.0335, LR: 1.93e-04
2025-12-05 17:57:07 ================================================================================
2025-12-05 17:57:07 [Epoch 34/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:31<00:00,  8.88it/s, loss=0.0340, lr=1.93e-04]
2025-12-05 17:59:39 
2025-12-05 17:59:39 [Epoch 34] Train - Loss: 0.0333, LR: 1.93e-04
2025-12-05 17:59:39 ================================================================================
2025-12-05 17:59:39 [Epoch 35/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:33<00:00,  8.80it/s, loss=0.0328, lr=1.93e-04]
2025-12-05 18:02:12 
2025-12-05 18:02:12 [Epoch 35] Train - Loss: 0.0332, LR: 1.93e-04
2025-12-05 18:02:12 [Epoch 35/1000] Running validation...
2025-12-05 18:02:12 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:12<00:00,  6.78it/s]
2025-12-05 18:03:13 
2025-12-05 18:03:13 [Validation Results]
2025-12-05 18:03:13   Val Loss: 0.0330
2025-12-05 18:03:13   Conf Loss: 0.0330
2025-12-05 18:03:13   mAP (tight): 0.5267
2025-12-05 18:03:13   mAP (loose): 0.7474
2025-12-05 18:03:13   mAP@1s: 0.4953
2025-12-05 18:03:13   mAP@2s: 0.5580
2025-12-05 18:03:13   mAP@3s: 0.5983
2025-12-05 18:03:13   mAP@5s: 0.6530
2025-12-05 18:03:13   mAP@10s: 0.7190
2025-12-05 18:03:13   mAP@20s: 0.7756
2025-12-05 18:03:13   mAP@30s: 0.8045
2025-12-05 18:03:13   mAP@60s: 0.8616
2025-12-05 18:03:13 ================================================================================
2025-12-05 18:03:13 [Epoch 36/1000] Training:   0%|                                                                                                                                          | 0/1347 [00:00<?, ?it/s]wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 18:03:15 [Epoch 36/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.73it/s, loss=0.0342, lr=1.93e-04]
2025-12-05 18:05:47 
2025-12-05 18:05:47 [Epoch 36] Train - Loss: 0.0330, LR: 1.93e-04
2025-12-05 18:05:47 ================================================================================
2025-12-05 18:05:47 [Epoch 37/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.69it/s, loss=0.0312, lr=1.93e-04]
2025-12-05 18:08:22 
2025-12-05 18:08:22 [Epoch 37] Train - Loss: 0.0331, LR: 1.93e-04
2025-12-05 18:08:22 ================================================================================
2025-12-05 18:08:22 [Epoch 38/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:33<00:00,  8.79it/s, loss=0.0319, lr=1.92e-04]
2025-12-05 18:10:56 
2025-12-05 18:10:56 [Epoch 38] Train - Loss: 0.0329, LR: 1.92e-04
2025-12-05 18:10:56 ================================================================================
2025-12-05 18:10:56 [Epoch 39/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.65it/s, loss=0.0383, lr=1.92e-04]
2025-12-05 18:13:31 
2025-12-05 18:13:31 [Epoch 39] Train - Loss: 0.0328, LR: 1.92e-04
2025-12-05 18:13:31 ================================================================================
2025-12-05 18:13:31 [Epoch 40/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:33<00:00,  8.78it/s, loss=0.0300, lr=1.92e-04]
2025-12-05 18:16:05 
2025-12-05 18:16:05 [Epoch 40] Train - Loss: 0.0330, LR: 1.92e-04
2025-12-05 18:16:05 [Epoch 40/1000] Running validation...
2025-12-05 18:16:05 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:12<00:00,  6.90it/s]
2025-12-05 18:17:07 
2025-12-05 18:17:07 [Validation Results]
2025-12-05 18:17:07   Val Loss: 0.0314
2025-12-05 18:17:07   Conf Loss: 0.0314
2025-12-05 18:17:07   mAP (tight): 0.5606
2025-12-05 18:17:07   mAP (loose): 0.7733
2025-12-05 18:17:07   mAP@1s: 0.5234
2025-12-05 18:17:07   mAP@2s: 0.5977
2025-12-05 18:17:07   mAP@3s: 0.6340
2025-12-05 18:17:07   mAP@5s: 0.6827
2025-12-05 18:17:07   mAP@10s: 0.7502
2025-12-05 18:17:07   mAP@20s: 0.8097
2025-12-05 18:17:07   mAP@30s: 0.8353
2025-12-05 18:17:07   mAP@60s: 0.8703
2025-12-05 18:17:09   ✓ Saved best model (mAP: 0.7733)
2025-12-05 18:17:11   ✓ Saved checkpoint at epoch 40
2025-12-05 18:17:11 ================================================================================
2025-12-05 18:17:11 [Epoch 41/1000] Training:   1%|▉                                                                                                      | 12/1347 [00:03<03:48,  5.83it/s, loss=0.0362, lr=1.92e-04]wandb: WARNING Tried to log to step 40 that is less than the current step 41. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 18:17:14 [Epoch 41/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:31<00:00,  8.88it/s, loss=0.0366, lr=1.92e-04]
2025-12-05 18:19:42 
2025-12-05 18:19:42 [Epoch 41] Train - Loss: 0.0326, LR: 1.92e-04
2025-12-05 18:19:42 ================================================================================
2025-12-05 18:19:42 [Epoch 42/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:32<00:00,  8.83it/s, loss=0.0284, lr=1.92e-04]
2025-12-05 18:22:15 
2025-12-05 18:22:15 [Epoch 42] Train - Loss: 0.0326, LR: 1.92e-04
2025-12-05 18:22:15 ================================================================================
2025-12-05 18:22:15 [Epoch 43/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.68it/s, loss=0.0312, lr=1.91e-04]
2025-12-05 18:24:50 
2025-12-05 18:24:50 [Epoch 43] Train - Loss: 0.0326, LR: 1.91e-04
2025-12-05 18:24:50 ================================================================================
2025-12-05 18:24:50 [Epoch 44/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:33<00:00,  8.76it/s, loss=0.0256, lr=1.91e-04]
2025-12-05 18:27:24 
2025-12-05 18:27:24 [Epoch 44] Train - Loss: 0.0324, LR: 1.91e-04
2025-12-05 18:27:24 ================================================================================
2025-12-05 18:27:24 [Epoch 45/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.69it/s, loss=0.0392, lr=1.91e-04]
2025-12-05 18:29:59 
2025-12-05 18:29:59 [Epoch 45] Train - Loss: 0.0326, LR: 1.91e-04
2025-12-05 18:29:59 [Epoch 45/1000] Running validation...
2025-12-05 18:29:59 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:13<00:00,  6.47it/s]
2025-12-05 18:31:02 
2025-12-05 18:31:02 [Validation Results]
2025-12-05 18:31:02   Val Loss: 0.0322
2025-12-05 18:31:02   Conf Loss: 0.0322
2025-12-05 18:31:02   mAP (tight): 0.5430
2025-12-05 18:31:02   mAP (loose): 0.7648
2025-12-05 18:31:02   mAP@1s: 0.5110
2025-12-05 18:31:02   mAP@2s: 0.5750
2025-12-05 18:31:02   mAP@3s: 0.6150
2025-12-05 18:31:02   mAP@5s: 0.6642
2025-12-05 18:31:02   mAP@10s: 0.7305
2025-12-05 18:31:02   mAP@20s: 0.7837
2025-12-05 18:31:02   mAP@30s: 0.8119
2025-12-05 18:31:02   mAP@60s: 0.8874
2025-12-05 18:31:02 ================================================================================
2025-12-05 18:31:02 [Epoch 46/1000] Training:   0%|                                                                                                                                          | 0/1347 [00:00<?, ?it/s]wandb: WARNING Tried to log to step 45 that is less than the current step 46. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 18:31:05 [Epoch 46/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.64it/s, loss=0.0330, lr=1.91e-04]
2025-12-05 18:33:38 
2025-12-05 18:33:38 [Epoch 46] Train - Loss: 0.0324, LR: 1.91e-04
2025-12-05 18:33:38 ================================================================================
2025-12-05 18:33:38 [Epoch 47/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.73it/s, loss=0.0352, lr=1.91e-04]
2025-12-05 18:36:13 
2025-12-05 18:36:13 [Epoch 47] Train - Loss: 0.0323, LR: 1.91e-04
2025-12-05 18:36:13 ================================================================================
2025-12-05 18:36:13 [Epoch 48/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.73it/s, loss=0.0366, lr=1.90e-04]
2025-12-05 18:38:47 
2025-12-05 18:38:47 [Epoch 48] Train - Loss: 0.0322, LR: 1.90e-04
2025-12-05 18:38:47 ================================================================================
2025-12-05 18:38:47 [Epoch 49/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:40<00:00,  8.41it/s, loss=0.0305, lr=1.90e-04]
2025-12-05 18:41:27 
2025-12-05 18:41:27 [Epoch 49] Train - Loss: 0.0321, LR: 1.90e-04
2025-12-05 18:41:27 ================================================================================
2025-12-05 18:41:27 [Epoch 50/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:36<00:00,  8.58it/s, loss=0.0291, lr=1.90e-04]
2025-12-05 18:44:04 
2025-12-05 18:44:04 [Epoch 50] Train - Loss: 0.0319, LR: 1.90e-04
2025-12-05 18:44:04 [Epoch 50/1000] Running validation...
2025-12-05 18:44:04 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:12<00:00,  6.97it/s]
2025-12-05 18:45:04 
2025-12-05 18:45:04 [Validation Results]
2025-12-05 18:45:04   Val Loss: 0.0339
2025-12-05 18:45:04   Conf Loss: 0.0339
2025-12-05 18:45:04   mAP (tight): 0.5707
2025-12-05 18:45:04   mAP (loose): 0.7743
2025-12-05 18:45:04   mAP@1s: 0.5414
2025-12-05 18:45:04   mAP@2s: 0.6001
2025-12-05 18:45:04   mAP@3s: 0.6367
2025-12-05 18:45:04   mAP@5s: 0.6862
2025-12-05 18:45:04   mAP@10s: 0.7536
2025-12-05 18:45:04   mAP@20s: 0.8109
2025-12-05 18:45:04   mAP@30s: 0.8345
2025-12-05 18:45:04   mAP@60s: 0.8704
2025-12-05 18:45:06   ✓ Saved best model (mAP: 0.7743)
2025-12-05 18:45:08   ✓ Saved checkpoint at epoch 50
2025-12-05 18:45:08 ================================================================================
2025-12-05 18:45:08 [Epoch 51/1000] Training:   2%|██▌                                                                                                    | 33/1347 [00:06<02:35,  8.47it/s, loss=0.0375, lr=1.90e-04]wandb: WARNING Tried to log to step 50 that is less than the current step 51. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-12-05 18:45:14 [Epoch 51/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.75it/s, loss=0.0291, lr=1.90e-04]
2025-12-05 18:47:42 
2025-12-05 18:47:42 [Epoch 51] Train - Loss: 0.0318, LR: 1.90e-04
2025-12-05 18:47:42 ================================================================================
2025-12-05 18:47:42 [Epoch 52/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:35<00:00,  8.64it/s, loss=0.0314, lr=1.90e-04]
2025-12-05 18:50:18 
2025-12-05 18:50:18 [Epoch 52] Train - Loss: 0.0319, LR: 1.90e-04
2025-12-05 18:50:18 ================================================================================
2025-12-05 18:50:18 [Epoch 53/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.70it/s, loss=0.0336, lr=1.89e-04]
2025-12-05 18:52:53 
2025-12-05 18:52:53 [Epoch 53] Train - Loss: 0.0320, LR: 1.89e-04
2025-12-05 18:52:53 ================================================================================
2025-12-05 18:52:53 [Epoch 54/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:39<00:00,  8.46it/s, loss=0.0315, lr=1.89e-04]
2025-12-05 18:55:32 
2025-12-05 18:55:32 [Epoch 54] Train - Loss: 0.0319, LR: 1.89e-04
2025-12-05 18:55:32 ================================================================================
2025-12-05 18:55:32 [Epoch 55/1000] Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1347/1347 [02:34<00:00,  8.72it/s, loss=0.0305, lr=1.89e-04]
2025-12-05 18:58:06 
2025-12-05 18:58:06 [Epoch 55] Train - Loss: 0.0327, LR: 1.89e-04
2025-12-05 18:58:06 [Epoch 55/1000] Running validation...
2025-12-05 18:58:06 Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:12<00:00,  6.88it/s]
2025-12-05 18:59:11 
2025-12-05 18:59:11 [Validation Results]
2025-12-05 18:59:11   Val Loss: 0.0326
2025-12-05 18:59:11   Conf Loss: 0.0326
2025-12-05 18:59:11   mAP (tight): 0.5301
2025-12-05 18:59:11   mAP (loose): 0.7484
2025-12-05 18:59:11   mAP@1s: 0.4980
2025-12-05 18:59:11   mAP@2s: 0.5621
2025-12-05 18:59:11   mAP@3s: 0.6008
2025-12-05 18:59:11   mAP@5s: 0.6504
2025-12-05 18:59:11   mAP@10s: 0.7198
2025-12-05 18:59:11   mAP@20s: 0.7826
2025-12-05 18:59:11   mAP@30s: 0.8113
2025-12-05 18:59:11   mAP@60s: 0.8580
